{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186a15b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Question 1: Generating Images with DCGAN\n",
    "Deep Convolutional GAN (DCGAN) is a type of GAN that uses convolutional networks in both the generator and discriminator. Here’s a brief outline for generating images from noise using a DCGAN in TensorFlow/Keras:\n",
    "\n",
    "Define the DCGAN Architecture:\n",
    "\n",
    "Generator: Takes random noise and generates images.\n",
    "Discriminator: Classifies images as real or fake.\n",
    "Train the DCGAN:\n",
    "\n",
    "Use the discriminator to classify real and generated images.\n",
    "Update the generator based on the discriminator’s feedback.\n",
    "Code Example:\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Reshape, Flatten, Conv2D, Conv2DTranspose\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "# Define the Generator\n",
    "def build_generator():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128 * 8 * 8, activation='relu', input_dim=100))\n",
    "    model.add(Reshape((8, 8, 128)))\n",
    "    model.add(Conv2DTranspose(128, kernel_size=4, strides=2, padding='same', activation='relu'))\n",
    "    model.add(Conv2DTranspose(64, kernel_size=4, strides=2, padding='same', activation='relu'))\n",
    "    model.add(Conv2DTranspose(3, kernel_size=7, activation='tanh', padding='same'))\n",
    "    return model\n",
    "\n",
    "# Define the Discriminator\n",
    "def build_discriminator():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(64, kernel_size=5, strides=2, padding='same', input_shape=(32, 32, 3)))\n",
    "    model.add(tf.keras.layers.LeakyReLU(alpha=0.2))\n",
    "    model.add(Conv2D(128, kernel_size=5, strides=2, padding='same'))\n",
    "    model.add(tf.keras.layers.LeakyReLU(alpha=0.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    return model\n",
    "\n",
    "# Compile the DCGAN\n",
    "def compile_gan(generator, discriminator):\n",
    "    discriminator.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    discriminator.trainable = False\n",
    "    gan_input = tf.keras.Input(shape=(100,))\n",
    "    x = generator(gan_input)\n",
    "    gan_output = discriminator(x)\n",
    "    gan = tf.keras.Model(gan_input, gan_output)\n",
    "    gan.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "    return gan\n",
    "\n",
    "generator = build_generator()\n",
    "discriminator = build_discriminator()\n",
    "gan = compile_gan(generator, discriminator)\n",
    "\n",
    "# Training function\n",
    "def train_gan(epochs, batch_size=128):\n",
    "    for epoch in range(epochs):\n",
    "        # Generate fake images\n",
    "        noise = tf.random.normal((batch_size, 100))\n",
    "        generated_images = generator.predict(noise)\n",
    "\n",
    "        # Combine with real images\n",
    "        # Note: In practice, you should load real images from a dataset\n",
    "\n",
    "        # Train Discriminator\n",
    "        d_loss_real = discriminator.train_on_batch(real_images, real_labels)\n",
    "        d_loss_fake = discriminator.train_on_batch(generated_images, fake_labels)\n",
    "        d_loss = 0.5 * tf.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "        # Train Generator\n",
    "        noise = tf.random.normal((batch_size, 100))\n",
    "        g_loss = gan.train_on_batch(noise, real_labels)\n",
    "\n",
    "        # Print progress\n",
    "        print(f\"{epoch}/{epochs} [D loss: {d_loss[0]} | D accuracy: {100 * d_loss[1]}] [G loss: {g_loss}]\")\n",
    "\n",
    "train_gan(epochs=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308e78b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Question 2: Fine-Tuning ResNet50 on CIFAR-10\n",
    "Steps to Fine-Tune ResNet50:\n",
    "\n",
    "Load the Pre-trained Model:\n",
    "\n",
    "Remove the top classification layer.\n",
    "Add Custom Layers:\n",
    "\n",
    "Add a new dense layer followed by a softmax layer.\n",
    "Compile and Train:\n",
    "\n",
    "Train on CIFAR-10 dataset.\n",
    "Code Example:\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load CIFAR-10 data\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "y_train, y_test = to_categorical(y_train, 10), to_categorical(y_test, 10)\n",
    "\n",
    "# Load ResNet50 model\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n",
    "x = base_model.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "predictions = Dense(10, activation='softmax')(x)\n",
    "\n",
    "# Compile model\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test))\n",
    "\n",
    "# Plot accuracies\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Test Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305a9145",
   "metadata": {},
   "outputs": [],
   "source": [
    "Question 3: GAN for Celebrity Faces\n",
    "Steps to Implement GAN:\n",
    "\n",
    "Load Data:\n",
    "\n",
    "Use the CelebA dataset.\n",
    "Define the GAN:\n",
    "\n",
    "Implement both the generator and discriminator.\n",
    "Train the GAN:\n",
    "\n",
    "Train the network and generate images.\n",
    "Code Example:\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Reshape, Flatten, Conv2D, Conv2DTranspose\n",
    "from tensorflow.keras.models import Sequential\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Load CelebA dataset\n",
    "# Code to load CelebA dataset here\n",
    "\n",
    "# Define the Generator and Discriminator as in Question 1\n",
    "\n",
    "# Compile and train the GAN\n",
    "# Similar to Question 1, include the training loop\n",
    "\n",
    "# Plot generator and discriminator losses\n",
    "# Example code to plot losses\n",
    "plt.plot(generator_losses, label='Generator Loss')\n",
    "plt.plot(discriminator_losses, label='Discriminator Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5920153",
   "metadata": {},
   "outputs": [],
   "source": [
    "Question 4: Minimax Loss Function for GANs\n",
    "Minimax Loss Function:\n",
    "\n",
    "\n",
    "def minimax_loss(y_true, y_pred):\n",
    "    return -tf.reduce_mean(tf.math.log(y_pred) * y_true + tf.math.log(1 - y_pred) * (1 - y_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c9f51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Question 5: Create a GAN Using CIFAR-10 Dataset\n",
    "Integrate Generator and Discriminator:\n",
    "\n",
    "\n",
    "# Define generator and discriminator from Question 2 and 3\n",
    "# Implement GAN and training loop using CIFAR-10 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db3d51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Question 6: Transfer Learning with GANs\n",
    "Load Pre-trained Model:\n",
    "\n",
    "Use VGG16 or ResNet50 as a feature extractor.\n",
    "Modify for GANs:\n",
    "\n",
    "Implement generator and discriminator using the pre-trained model.\n",
    "Train and Evaluate:\n",
    "\n",
    "Evaluate generated images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0adb25",
   "metadata": {},
   "outputs": [],
   "source": [
    "Question 7: Basic GAN for MNIST\n",
    "GAN for MNIST:\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Reshape, Flatten\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "# Define generator and discriminator\n",
    "# Implement training loop\n",
    "# Generate and display sample images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b308a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Question 8: Deep Convolutional GAN (DCGAN)\n",
    "DCGAN Architecture:\n",
    "\n",
    "Generator: Uses transpose convolutions to upsample random noise.\n",
    "Discriminator: Uses convolutions to downsample images.\n",
    "Conditional GAN for Fashion MNIST:\n",
    "\n",
    "\n",
    "from tensorflow.keras.layers import Input, Dense, Embedding, Flatten, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Define the generator and discriminator for conditional GAN\n",
    "# Use fashion_mnist dataset\n",
    "Additional Considerations\n",
    "Data Augmentation Function: Implement augmentations using libraries such as OpenCV or PIL.\n",
    "Tips for GAN Training: Use techniques such as label smoothing, one-sided label smoothing, and gradient penalty to improve training stability.\n",
    "For detailed implementations, you might need to adapt the examples to your specific use case and dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d5d4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q 9. A Conditional GAN (cGAN) generates images based on additional information or conditions. For Fashion MNIST, this means generating images conditioned on the class labels (e.g., \"t-shirt\", \"dress\", etc.).\n",
    "\n",
    "Steps\n",
    "Load and Prepare the Data:\n",
    "\n",
    "Load Fashion MNIST dataset.\n",
    "Preprocess and prepare the dataset for training.\n",
    "Define the Conditional GAN Architecture:\n",
    "\n",
    "Generator: Takes both noise and class labels as input to generate images.\n",
    "Discriminator: Takes an image and class label to classify the image as real or fake.\n",
    "Compile and Train the cGAN:\n",
    "\n",
    "Train the discriminator and generator alternately.\n",
    "Code Implementation\n",
    "Here's a complete implementation using TensorFlow and Keras:\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Reshape, Flatten, Concatenate, Embedding, Input, Conv2D, Conv2DTranspose\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load Fashion MNIST dataset\n",
    "(x_train, y_train), (_, _) = fashion_mnist.load_data()\n",
    "x_train = (x_train.astype(np.float32) - 127.5) / 127.5  # Normalize to [-1, 1]\n",
    "x_train = np.expand_dims(x_train, axis=-1)  # Add channel dimension\n",
    "\n",
    "# One-hot encode labels\n",
    "y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
    "\n",
    "# Define the generator\n",
    "def build_generator():\n",
    "    noise_input = Input(shape=(100,))\n",
    "    label_input = Input(shape=(10,))\n",
    "    \n",
    "    # Combine noise and label inputs\n",
    "    x = Concatenate()([noise_input, label_input])\n",
    "    \n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dense(7 * 7 * 64, activation='relu')(x)\n",
    "    x = Reshape((7, 7, 64))(x)\n",
    "    \n",
    "    x = Conv2DTranspose(64, kernel_size=4, strides=2, padding='same', activation='relu')(x)\n",
    "    x = Conv2DTranspose(1, kernel_size=4, strides=2, padding='same', activation='tanh')(x)\n",
    "    \n",
    "    model = Model([noise_input, label_input], x)\n",
    "    return model\n",
    "\n",
    "# Define the discriminator\n",
    "def build_discriminator():\n",
    "    img_input = Input(shape=(28, 28, 1))\n",
    "    label_input = Input(shape=(10,))\n",
    "    \n",
    "    # Process image\n",
    "    x = Conv2D(64, kernel_size=3, strides=2, padding='same')(img_input)\n",
    "    x = tf.keras.layers.LeakyReLU(alpha=0.2)(x)\n",
    "    x = Conv2D(128, kernel_size=3, strides=2, padding='same')(x)\n",
    "    x = tf.keras.layers.LeakyReLU(alpha=0.2)(x)\n",
    "    x = Flatten()(x)\n",
    "    \n",
    "    # Process label\n",
    "    y = Dense(128, activation='relu')(label_input)\n",
    "    \n",
    "    # Combine image and label\n",
    "    combined = Concatenate()([x, y])\n",
    "    combined = Dense(1, activation='sigmoid')(combined)\n",
    "    \n",
    "    model = Model([img_input, label_input], combined)\n",
    "    return model\n",
    "\n",
    "# Compile the models\n",
    "def compile_gan(generator, discriminator):\n",
    "    discriminator.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    discriminator.trainable = False\n",
    "    \n",
    "    noise_input = Input(shape=(100,))\n",
    "    label_input = Input(shape=(10,))\n",
    "    \n",
    "    gen_img = generator([noise_input, label_input])\n",
    "    gan_output = discriminator([gen_img, label_input])\n",
    "    \n",
    "    gan = Model([noise_input, label_input], gan_output)\n",
    "    gan.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "    \n",
    "    return gan\n",
    "\n",
    "# Build and compile models\n",
    "generator = build_generator()\n",
    "discriminator = build_discriminator()\n",
    "gan = compile_gan(generator, discriminator)\n",
    "\n",
    "# Training function\n",
    "def train_gan(epochs, batch_size=128):\n",
    "    for epoch in range(epochs):\n",
    "        # Generate fake images\n",
    "        noise = np.random.normal(0, 1, (batch_size, 100))\n",
    "        labels = np.random.randint(0, 10, batch_size)\n",
    "        labels_one_hot = tf.keras.utils.to_categorical(labels, 10)\n",
    "        generated_images = generator.predict([noise, labels_one_hot])\n",
    "        \n",
    "        # Create real and fake labels\n",
    "        real_labels = np.ones((batch_size, 1))\n",
    "        fake_labels = np.zeros((batch_size, 1))\n",
    "        \n",
    "        # Train discriminator\n",
    "        real_images = x_train[np.random.randint(0, x_train.shape[0], batch_size)]\n",
    "        real_labels_discriminator = y_train[np.random.randint(0, y_train.shape[0], batch_size)]\n",
    "        \n",
    "        d_loss_real = discriminator.train_on_batch([real_images, real_labels_discriminator], real_labels)\n",
    "        d_loss_fake = discriminator.train_on_batch([generated_images, labels_one_hot], fake_labels)\n",
    "        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "        \n",
    "        # Train generator\n",
    "        noise = np.random.normal(0, 1, (batch_size, 100))\n",
    "        labels = np.random.randint(0, 10, batch_size)\n",
    "        labels_one_hot = tf.keras.utils.to_categorical(labels, 10)\n",
    "        g_loss = gan.train_on_batch([noise, labels_one_hot], real_labels)\n",
    "        \n",
    "        # Print progress\n",
    "        if (epoch + 1) % 100 == 0:\n",
    "            print(f\"Epoch: {epoch + 1}, D Loss: {d_loss[0]}, D Accuracy: {100 * d_loss[1]}, G Loss: {g_loss}\")\n",
    "\n",
    "train_gan(epochs=10000)\n",
    "\n",
    "# Generate sample images\n",
    "def generate_images(generator, num_images=10):\n",
    "    noise = np.random.normal(0, 1, (num_images, 100))\n",
    "    labels = np.arange(num_images) % 10\n",
    "    labels_one_hot = tf.keras.utils.to_categorical(labels, 10)\n",
    "    generated_images = generator.predict([noise, labels_one_hot])\n",
    "    generated_images = (generated_images + 1) / 2.0  # Rescale to [0, 1]\n",
    "    \n",
    "    fig, axes = plt.subplots(1, num_images, figsize=(10, 1))\n",
    "    for i in range(num_images):\n",
    "        axes[i].imshow(generated_images[i].reshape(28, 28), cmap='gray')\n",
    "        axes[i].axis('off')\n",
    "    plt.show()\n",
    "\n",
    "generate_images(generator)\n",
    "Explanation\n",
    "Data Preparation:\n",
    "\n",
    "Fashion MNIST images are normalized to [-1, 1] and labels are one-hot encoded.\n",
    "Model Definition:\n",
    "\n",
    "Generator: Takes noise and labels as input and generates images.\n",
    "Discriminator: Takes images and labels as input and classifies them as real or fake.\n",
    "Training:\n",
    "\n",
    "Discriminator is trained on real and generated images.\n",
    "Generator is trained to fool the discriminator.\n",
    "Image Generation:\n",
    "\n",
    "Generate and display sample images based on class labels.\n",
    "This implementation should give you a functional Conditional GAN that generates images from the Fashion MNIST dataset based on class labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b719af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
